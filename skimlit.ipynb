{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf;\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "import keras.backend as k;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"pubmed-rct-master/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBTAIN THE DATA ABOUT THE NUMBER OF FILES WE HAVE IN THE DIRECTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pubmed-rct-master/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt', 'pubmed-rct-master/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt', 'pubmed-rct-master/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']\n"
     ]
    }
   ],
   "source": [
    "import os;\n",
    "filename=[data_dir+filename for filename in os.listdir(data_dir)]\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AND THEN WE CREATE A FUNCTION TO READ THE LINES OF THE FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines(filename):\n",
    "    with open(filename,\"r\")as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE CREATE A FUNCTION TO PREPROCESS THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(filename):\n",
    "    input_lines=get_lines(filename)#read input from the file\n",
    "    abstract_lines=\"\"#create an empty string\n",
    "    abstract_samples=[]#create an empty list to concatenate later\n",
    "    for line in input_lines:\n",
    "        if line.startswith(\"###\"):# if the line starts with ### we say it is an ID so abstract id is equal to id\n",
    "            abstract_id=line\n",
    "            abstract_lines=\"\"#we reset the abstract line here\n",
    "        elif line.isspace():#to check if there is a new line we use this method!\n",
    "            abstract_line_split=abstract_lines.splitlines()#if there is a new line we split it right there\n",
    "            for abstract_line_number,abstract_line in enumerate(abstract_line_split):#now in that split we find which is the target,text,etc\n",
    "                line_data={}#we create an empty dict and make use of enumerate to keep track of the line number.\n",
    "                target_text_split=abstract_line.split(\"\\t\")#we split the data when we have found a tabspace and after that the data that \n",
    "                line_data[\"target\"]=target_text_split[0]#remains in the first index is the target and the words next to it are considered\n",
    "                line_data[\"text\"]=target_text_split[1]# as texts \n",
    "                line_data[\"line_number\"]=abstract_line_number\n",
    "                line_data[\"total_lines\"]=len(abstract_line_split)\n",
    "                abstract_samples.append(line_data)#here we append the dictionary to the original abstract sample list!\n",
    "        else:#if the above conditions arent fulfilled then the sentence is labelled sentence so just concatenate the line\n",
    "            abstract_lines +=line\n",
    "    return abstract_samples                \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE OBTAIN THE TRAIN DATA,TEST DATA,VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 359 ms\n",
      "Wall time: 362 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30212, 180040, 30135)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "train_samples=preprocess_text(data_dir+\"train.txt\")#Note that we use %%time to obtain the cpu time taken to execute and wall time \n",
    "test_samples=preprocess_text(data_dir+\"test.txt\")\n",
    "val_samples=preprocess_text(data_dir+\"dev.txt\")\n",
    "len(val_samples),len(train_samples),len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'target': 'OBJECTIVE',\n",
       "  'text': 'To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .',\n",
       "  'line_number': 0,\n",
       "  'total_lines': 12},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       "  'line_number': 1,\n",
       "  'total_lines': 12},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       "  'line_number': 2,\n",
       "  'total_lines': 12},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'Pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       "  'line_number': 3,\n",
       "  'total_lines': 12},\n",
       " {'target': 'METHODS',\n",
       "  'text': 'Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .',\n",
       "  'line_number': 4,\n",
       "  'total_lines': 12}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE CREATE THE DATAFRAME FOR THE SAMPLES USING PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>To investigate the efficacy of @ weeks of dail...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>A total of @ patients with primary knee OA wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Outcome measures included pain reduction and i...</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Pain was assessed using the visual analog pain...</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Secondary outcome measures included the Wester...</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Serum levels of interleukin @ ( IL-@ ) , IL-@ ...</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>There was a clinically relevant reduction in t...</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>The mean difference between treatment arms ( @...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Further , there was a clinically relevant redu...</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>These differences remained significant at @ we...</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                               text  line_number  \\\n",
       "0  OBJECTIVE  To investigate the efficacy of @ weeks of dail...            0   \n",
       "1    METHODS  A total of @ patients with primary knee OA wer...            1   \n",
       "2    METHODS  Outcome measures included pain reduction and i...            2   \n",
       "3    METHODS  Pain was assessed using the visual analog pain...            3   \n",
       "4    METHODS  Secondary outcome measures included the Wester...            4   \n",
       "5    METHODS  Serum levels of interleukin @ ( IL-@ ) , IL-@ ...            5   \n",
       "6    RESULTS  There was a clinically relevant reduction in t...            6   \n",
       "7    RESULTS  The mean difference between treatment arms ( @...            7   \n",
       "8    RESULTS  Further , there was a clinically relevant redu...            8   \n",
       "9    RESULTS  These differences remained significant at @ we...            9   \n",
       "\n",
       "   total_lines  \n",
       "0           12  \n",
       "1           12  \n",
       "2           12  \n",
       "3           12  \n",
       "4           12  \n",
       "5           12  \n",
       "6           12  \n",
       "7           12  \n",
       "8           12  \n",
       "9           12  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.DataFrame(train_samples)\n",
    "test_df=pd.DataFrame(test_samples)\n",
    "val_df=pd.DataFrame(val_samples)\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW THAT OUR DATA IS A DATAFRAME WE CAN DO SOME ANALYSIS ON IT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "METHODS        59353\n",
       "RESULTS        57953\n",
       "CONCLUSIONS    27168\n",
       "BACKGROUND     21727\n",
       "OBJECTIVE      13839\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.total_lines.plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we get a list of sentences.. one of the most important inputs of the deeplearning model..\n",
    "we get these easily by calling our dataframe into a list using the list() function on our \"text\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences=train_df[\"text\"].tolist()\n",
    "test_sentences=test_df[\"text\"].tolist()\n",
    "val_sentences=val_df[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180040, 30212, 30135)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences),len(val_sentences),len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .',\n",
       " 'A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
       " 'Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
       " 'Pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
       " 'Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .',\n",
       " 'Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .',\n",
       " 'There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .',\n",
       " 'The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
       " 'Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .',\n",
       " 'These differences remained significant at @ weeks .']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE CONVERT THE TEXT INTO NUMERICAL VARIABLES, WE COULD JUST DO LABEL ENCODING AND BE FINE WITH IT BUT TENSORFLOW's CATEGORICAL CROSSENTROPY LOSS FUNCTION LIKES TO HAVE ONE HOT ENCODED LABELS SO WE KNOW NN LOVES NORMALIZED MODELS SO WE DO THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder;\n",
    "one_hot_encoder=OneHotEncoder(sparse=False)\n",
    "train_df_one_hot=one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1,1))\n",
    "test_df_one_hot=one_hot_encoder.fit_transform(test_df[\"target\"].to_numpy().reshape(-1,1))\n",
    "val_df_one_hot=one_hot_encoder.fit_transform(val_df[\"target\"].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HERE WE ENCODED THE TARGET SECTION OF THE DATAFRAME WHICH IS A CATEGORY.WE SET THE SPARSE VALUE TO FALSE TO NOT MAKE IT DENSE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_one_hot[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE LABEL ENCODE THE LABELS USING LABEL ENCODER FROM SKLEARN TO GET THE NUMBER OF CLASSES AND CLASS NAMES!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Anaconda\\envs\\tensorflow_env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder;\n",
    "label_encoder=LabelEncoder()\n",
    "train_labels_encoded=label_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1,1))\n",
    "test_labels_encoded=label_encoder.fit_transform(test_df[\"target\"].to_numpy().reshape(-1,1))\n",
    "val_labels_encoded=label_encoder.fit_transform(val_df[\"target\"].to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_encoded[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBTAINED THE NO OF CLASSES AND THE NAMES OF THE CLASSES!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 ['BACKGROUND' 'CONCLUSIONS' 'METHODS' 'OBJECTIVE' 'RESULTS']\n"
     ]
    }
   ],
   "source": [
    "num_classes=len(label_encoder.classes_)\n",
    "class_names=label_encoder.classes_\n",
    "print(num_classes,class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE ARE DONE PREPROCESSING THE MODEL TIME TO GET INTO SOME MODELLING EXPERIMENTS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ********************************** MODEL_0 (BASELINE MODEL) *****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB;\n",
    "from sklearn.pipeline import Pipeline;\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer;\n",
    "model_0=Pipeline([\n",
    "    (\"tfidf\",TfidfVectorizer()),\n",
    "    (\"clf\",MultinomialNB())\n",
    "])\n",
    "model_0.fit(X=train_sentences,y=train_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7218323844829869"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0.score(X=val_sentences,y=val_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 1, 3, ..., 4, 4, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_preds=model_0.predict(X=val_sentences)\n",
    "baseline_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NOW WE PREPARE OUR DATA FOR DEEP SEQUENCE MODELS!\n",
    " WE HAVE TO DO TWO THINGS:\n",
    " 1:Tokenization\n",
    " 2:Embedding \n",
    " THESE ARE VERY ESSENTIAL STEPS IN BUILDING AN NLP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE GOTTA TUNE OUR SENTENCES TO NUMBERS AND THUS IT IS A GOOD IDEA TO FIGURE OUT HOW MUCH WORDS ARE IN A SENTENCE.BECAUSE OUR MODEL WORKS BEST IF EACH SENTENCES ARE OF EQUAL LENGTH WHICH THEN IS CONVERTED TO BATCHES AND FIT IN THE MODEL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR EXAMPLE IF A SENTENCE IS 15 WORDS LONG AND THE OTHER SENTENCE IS 20 WORDS LONG WE HAVE TO PAD THE 5 MISSING WORDS WITH 0's AND IT ENDS UP BEING THE SAME LENGTH AS THE LAST SENTENCE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.338269273494777"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_len=[len(sentence.split()) for sentence in train_sentences]# How long is each sentence on average?\n",
    "avg_sen_len=np.mean(sentence_len)\n",
    "avg_sen_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.5999e+05, 1.8760e+04, 1.1510e+03, 9.9000e+01, 2.8000e+01,\n",
       "        1.0000e+01, 2.0000e+00]),\n",
       " array([  1.        ,  43.14285714,  85.28571429, 127.42857143,\n",
       "        169.57142857, 211.71428571, 253.85714286, 296.        ]),\n",
       " <BarContainer object of 7 artists>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt;\n",
    "plt.hist(sentence_len,bins=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_seq_len=np.percentile(sentence_len,95)\n",
    "output_seq_len# this means that how long of a sentence covers 95% of the length\n",
    "#it looks like 95% of the sentences in our train sentences have 55 words/tokens in thier dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHEN WE CREATE OUR TOKENIZATION LAYERS WE USE THIS VALUE TO TURN ALL OUR SENTENCE TO THE SAME LENGTH! MEANING ALL THE SENTENCES BELOW THIS NUMBER GETS PADDED WITH ZEROS!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NOW WE CREATE THE TEXT VECTORIZER WE ONLY MODIFY max_tokens and the output_Sequence_length and keep rest of the parameters to default!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization;\n",
    "text_vectorizer=TextVectorization(max_tokens=68000,output_sequence_length=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence:Processing conditions have a large effect on the kinetics and bioavailability of isothiocyanates from broccoli .\n",
      "Length of sentence:16\n",
      "Vectorized sentence:[[ 2573   458    99     8   545    70    18     2  3940     3  2760     4\n",
      "  30566    27 13465     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "import random;\n",
    "target_sentence=random.choice(train_sentences)\n",
    "print(f\"sentence:{target_sentence}\")\n",
    "print(f\"Length of sentence:{len(target_sentence.split())}\")\n",
    "print(f\"Vectorized sentence:{text_vectorizer([target_sentence])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words in the vocabulary: 64841\n",
      "the most commmon used words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n",
      "the least used words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
     ]
    }
   ],
   "source": [
    "# WE CAN GET THE STEREOTYPES OF VOCABULARIES OF THE VECTORIZED SENTENCES USING get_vocabulary method\n",
    "text_vocab=text_vectorizer.get_vocabulary()\n",
    "print(f\"number of words in the vocabulary: {len(text_vocab)}\")\n",
    "print(f\"the most commmon used words in the vocabulary: {text_vocab[:5]}\")\n",
    "print(f\"the least used words in the vocabulary: {text_vocab[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'text_vectorization',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None,),\n",
       " 'dtype': 'string',\n",
       " 'max_tokens': 68000,\n",
       " 'standardize': 'lower_and_strip_punctuation',\n",
       " 'split': 'whitespace',\n",
       " 'ngrams': None,\n",
       " 'output_mode': 'int',\n",
       " 'output_sequence_length': 55,\n",
       " 'pad_to_max_tokens': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE DO THE STEP OF EMBEDDING.. ALTHOUGH THE VECTORIZATION DOES THE CONVERSION OF WORDS TO NUMBERS IT DOESNT NECESSARILY MEAN WE ARE DONE.. FOR OUR NN MODEL TO UNDERSTAND THE DATA WE CONVERT THE NUMBERS TO VECTORS BY USING THE EMBEDDING LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a token embedding layer\n",
    "token_embed=layers.Embedding(input_dim=len(text_vocab),output_dim=128,#different embedding sizes result in diff number of parameters to train\n",
    "                             embeddings_initializer=\"uniform\",mask_zero=True,#we use masking to handle variable sequence length to save space\n",
    "                             name=\"token_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 2573   458    99     8   545    70    18     2  3940     3  2760     4\n",
      "  30566    27 13465     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]], shape=(1, 55), dtype=int64) (1, 55)\n"
     ]
    }
   ],
   "source": [
    "vectorized_sentence=text_vectorizer([target_sentence])\n",
    "print(vectorized_sentence,vectorized_sentence.shape) # u can see the output words is of length 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.04777322  0.00605954 -0.02080641 ...  0.0152715  -0.03261013\n",
      "    0.00192512]\n",
      "  [-0.01762604  0.01562728  0.04527584 ... -0.01570773 -0.00540014\n",
      "   -0.01733656]\n",
      "  [ 0.03886446  0.01918742 -0.03928374 ... -0.00255007  0.0108964\n",
      "    0.00860987]\n",
      "  ...\n",
      "  [-0.00224762  0.01723696  0.04666171 ...  0.0062607  -0.01528393\n",
      "    0.0377068 ]\n",
      "  [-0.00224762  0.01723696  0.04666171 ...  0.0062607  -0.01528393\n",
      "    0.0377068 ]\n",
      "  [-0.00224762  0.01723696  0.04666171 ...  0.0062607  -0.01528393\n",
      "    0.0377068 ]]], shape=(1, 55, 128), dtype=float32) (1, 55, 128)\n"
     ]
    }
   ],
   "source": [
    "embedded_sentence=token_embed(vectorized_sentence)\n",
    "print(embedded_sentence,embedded_sentence.shape)# u can see the output shape is 128 with 55 words in its arsenal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO CREATE DATASETS AS FAST AS POSSIBLE there is this API called as the tf.data which enables faster data loading. we have gone through \n",
    "so many steps to preprocess the data but there are still a few steps that we can take to make it load faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so now we turn our data into tensorflow datasets\n",
    "train_dataset=tf.data.Dataset.from_tensor_slices((train_sentences,train_df_one_hot))\n",
    "test_dataset=tf.data.Dataset.from_tensor_slices((test_sentences,test_df_one_hot))\n",
    "val_dataset=tf.data.Dataset.from_tensor_slices((val_sentences,val_df_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we take these datasets and turn them into the prefetch batches\n",
    "train_dataset=train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset=test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)#the tf,data.AUTOTUNE  will allow tensorflow to  determine the optimal \n",
    "val_dataset=val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)#amount of compute  to use to prepare the datasets\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ******************************** MODEL 1:CONV1D WITH TOKEN EMBEDDINGS! *********************************\n",
    "                    Input(text) -> Tokenize/Vectorize -> Embedding ->layers -> Output (labels/probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1D convolutional model to process sequences\n",
    "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
    "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
    "token_embeddings = token_embed(text_vectors) # create embedding\n",
    "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
    "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "model_1 = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile\n",
    "model_1.compile(loss=\"categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 13s 8ms/step - loss: 0.9156 - accuracy: 0.6422 - val_loss: 0.6866 - val_accuracy: 0.7426\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 4s 8ms/step - loss: 0.6540 - accuracy: 0.7581 - val_loss: 0.6364 - val_accuracy: 0.7715\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 4s 8ms/step - loss: 0.6147 - accuracy: 0.7755 - val_loss: 0.5950 - val_accuracy: 0.7882\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 4s 8ms/step - loss: 0.5885 - accuracy: 0.7884 - val_loss: 0.5742 - val_accuracy: 0.7938\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 4s 8ms/step - loss: 0.5902 - accuracy: 0.7939 - val_loss: 0.5623 - val_accuracy: 0.8016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1db1a7fa220>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(train_dataset,epochs=5,steps_per_epoch=(0.1*len(train_dataset)),validation_data=val_dataset,validation_steps=(0.25*len(val_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 2s 2ms/step - loss: 0.5599 - accuracy: 0.8017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5599410533905029, 0.8017013072967529]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_preds=model_1.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " *********************** MODEL 2: FEATURE EXTRACTION WITH PRETRAINED MODEL EMBEDDINGS *******************************\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download pretrained TensorFlow Hub USE\n",
    "import tensorflow_hub as hub\n",
    "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "                                        trainable=False,\n",
    "                                        name=\"universal_sentence_encoder\")\n",
    "#note that the USE embedding layer outputs a 512 dimensional vector unlike our previous model that outputs 128 dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extractor model using TF Hub layer\n",
    "inputs = layers.Input(shape=[],dtype=tf.string)\n",
    "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
    "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
    "# Note: you could add more layers here if you wanted to\n",
    "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
    "model_2 = tf.keras.Model(inputs=inputs,\n",
    "                        outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model_2.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None,)]                 0         \n",
      "_________________________________________________________________\n",
      "universal_sentence_encoder ( (None, 512)               256797824 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 256,864,133\n",
      "Trainable params: 66,309\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 9s 12ms/step - loss: 0.9152 - accuracy: 0.6506 - val_loss: 0.7955 - val_accuracy: 0.6878\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 7s 12ms/step - loss: 0.7689 - accuracy: 0.7021 - val_loss: 0.7567 - val_accuracy: 0.7045\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 7s 12ms/step - loss: 0.7538 - accuracy: 0.7109 - val_loss: 0.7410 - val_accuracy: 0.7098\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 7s 12ms/step - loss: 0.7200 - accuracy: 0.7229 - val_loss: 0.7133 - val_accuracy: 0.7271\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 7s 12ms/step - loss: 0.7269 - accuracy: 0.7208 - val_loss: 0.6924 - val_accuracy: 0.7340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dd88154c40>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train_dataset,\n",
    "    steps_per_epoch=int(0.1 * len(train_dataset)),\n",
    "    epochs=5,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=int(0.1 * len(val_dataset)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TRAINING THE MODEL WITH CHARACTER BASED TOKEN EMBEDDING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'V a r i a b l e s   i n c l u d i n g   l e n g t h   o f   h o s p i t a l i s a t i o n   ,   t i m e   f o r   w o u n d   h e a l i n g   ,   t i m e   o f f   w o r k   ,   r e c u r r e n c e   a n d   s u r g i c a l   c o m p l i c a t i o n s   w e r e   e v a l u a t e d   .'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_chars(text):\n",
    "    return \" \".join(text)\n",
    "split_chars(random.choice(train_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chars=[split_chars(text)for text in train_sentences]\n",
    "test_chars=[split_chars(text)for text in test_sentences]\n",
    "val_chars=[split_chars(text)for text in val_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   O A   )   .',\n",
       " 'A   t o t a l   o f   @   p a t i e n t s   w i t h   p r i m a r y   k n e e   O A   w e r e   r a n d o m i z e d   @ : @   ;   @   r e c e i v e d   @   m g / d a y   o f   p r e d n i s o l o n e   a n d   @   r e c e i v e d   p l a c e b o   f o r   @   w e e k s   .',\n",
       " 'O u t c o m e   m e a s u r e s   i n c l u d e d   p a i n   r e d u c t i o n   a n d   i m p r o v e m e n t   i n   f u n c t i o n   s c o r e s   a n d   s y s t e m i c   i n f l a m m a t i o n   m a r k e r s   .',\n",
       " 'P a i n   w a s   a s s e s s e d   u s i n g   t h e   v i s u a l   a n a l o g   p a i n   s c a l e   (   @ - @   m m   )   .',\n",
       " 'S e c o n d a r y   o u t c o m e   m e a s u r e s   i n c l u d e d   t h e   W e s t e r n   O n t a r i o   a n d   M c M a s t e r   U n i v e r s i t i e s   O s t e o a r t h r i t i s   I n d e x   s c o r e s   ,   p a t i e n t   g l o b a l   a s s e s s m e n t   (   P G A   )   o f   t h e   s e v e r i t y   o f   k n e e   O A   ,   a n d   @ - m i n   w a l k   d i s t a n c e   (   @ M W D   )   .']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_chars[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149.3662574983337"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_lens=[len(i)for i in train_sentences]\n",
    "np.mean(char_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    }
   ],
   "source": [
    "output_seq_char_len=int(np.percentile(char_lens,95))\n",
    "print(output_seq_char_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.69034e+05, 1.07780e+04, 2.09000e+02, 1.60000e+01, 3.00000e+00]),\n",
       " array([1.000e+00, 2.780e+02, 5.550e+02, 8.320e+02, 1.109e+03, 1.386e+03]),\n",
       " <BarContainer object of 5 artists>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt;\n",
    "plt.hist(char_lens,bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IN EMBEDDING LAYER WE SET MAX TOKENS TO 28 i.e., THE 26 LETTERS OF THE ALPHABET AND ONE SPACE CHAR AND THE UNKNOWN TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string;\n",
    "print(string.ascii_lowercase+string.digits+string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING A CHAR LEVEL TOKEN VECTORIZER INSTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens=26+2 # no of aplhabets and a space and unexpected token\n",
    "char_vectorizer=TextVectorization(max_tokens=num_tokens,\n",
    "                                output_sequence_length=output_seq_char_len,#make sure this sequence length is int!\n",
    "                                standardize=\"lower_and_strip_punctuation\" #lower and strip method\n",
    "                                )\n",
    "char_vectorizer.adapt(train_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens in char vocabulary:28\n",
      "Most common tokens:['', '[UNK]', 'e', 't', 'i']\n",
      "Least common tokens:['k', 'x', 'z', 'q', 'j']\n"
     ]
    }
   ],
   "source": [
    "char_vocab=char_vectorizer.get_vocabulary()\n",
    "print(f\"number of tokens in char vocabulary:{len(char_vocab)}\")\n",
    "print(f\"Most common tokens:{char_vocab[:5]}\")\n",
    "print(f\"Least common tokens:{char_vocab[-5:]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING THE CHARACTER EMBEDDING LAYER..HERE INPUT DIM IS NUM OF TOKENS AND OUTPUT DIM IS SET TO 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embed=tf.keras.layers.Embedding(input_dim=num_tokens,\n",
    "                                     output_dim=25,\n",
    "                                     \n",
    "                                     mask_zero=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHAR TOKEN BASED EMBEDDING MODEL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=tf.keras.layers.Input(shape=(1,),dtype=\"string\")\n",
    "char_vec=char_vectorizer(inputs)\n",
    "embeds=char_embed(char_vec)\n",
    "x=tf.keras.layers.Conv1D(64,kernel_size=5,padding=\"same\",activation=\"relu\")(embeds)\n",
    "x=tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs=tf.keras.layers.Dense(5,activation=\"sigmoid\")(x)\n",
    "model_3=tf.keras.Model(inputs,outputs)\n",
    "model_3.compile(loss=tf.keras.losses.CategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(),metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_char_dataset=tf.data.Dataset.from_tensor_slices((train_chars,train_df_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_char_dataset=tf.data.Dataset.from_tensor_slices((val_chars,val_df_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_char_dataset=tf.data.Dataset.from_tensor_slices((test_chars,test_df_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 4s 6ms/step - loss: 1.4549 - accuracy: 0.3490 - val_loss: 1.3988 - val_accuracy: 0.3990\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 3s 6ms/step - loss: 1.3612 - accuracy: 0.4234 - val_loss: 1.3319 - val_accuracy: 0.4408\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 3s 5ms/step - loss: 1.3224 - accuracy: 0.4535 - val_loss: 1.3114 - val_accuracy: 0.4513\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 2s 4ms/step - loss: 1.2956 - accuracy: 0.4592 - val_loss: 1.2894 - val_accuracy: 0.4658\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 3s 5ms/step - loss: 1.2892 - accuracy: 0.4563 - val_loss: 1.2818 - val_accuracy: 0.4720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ddd4769100>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(train_char_dataset,epochs=5,steps_per_epoch=(0.1*len(train_char_dataset)),validation_data=val_char_dataset,validation_steps=(0.1*len(val_char_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1)]               0         \n",
      "_________________________________________________________________\n",
      "text_vectorization_1 (TextVe (None, 290)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 290, 25)           700       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 290, 64)           8064      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 9,089\n",
      "Trainable params: 9,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 3s 3ms/step - loss: 1.2813 - accuracy: 0.4723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2812995910644531, 0.47232887148857117]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(val_char_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 4 CREATING AN HYBRID OF CHAR BASED MODEL AND PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE THE TOKEN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_inputs=layers.Input(shape=[],dtype=tf.string,name=\"token_input\")\n",
    "token_embedding=tf_hub_embedding_layer(token_inputs)\n",
    "token_outputs=layers.Dense(128,activation=\"relu\")(token_embedding)\n",
    "token_model=tf.keras.Model(token_inputs,token_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATE THE CHAR MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_input=layers.Input(shape=(1,),dtype=\"string\")\n",
    "char_vectors=char_vectorizer(char_input)\n",
    "char_embedding=char_embed(char_vectors)\n",
    "char_layer_bilstm=layers.Bidirectional(layers.LSTM(25))(char_embedding)# no need to define activation over here!\n",
    "char_model=tf.keras.Model(char_input,char_layer_bilstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW CONCATENATE TOKEN AND CHAR MODEL's INPUT AND OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_char_concat=layers.concatenate([token_model.output,char_model.output])\n",
    "\n",
    "combined_dropout=layers.Dropout(0.5)(token_char_concat)\n",
    "combined_dense=layers.Dense(200,activation=\"relu\")(combined_dropout)\n",
    "final_dropout=layers.Dropout(0.5)(combined_dense)\n",
    "output_layer=layers.Dense(num_classes,activation=\"softmax\")(final_dropout)\n",
    "\n",
    "model_4=tf.keras.Model(inputs=[token_model.input,char_model.input],outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dropout layer randomly sets input units to 0 with a frequency of rate at each step during training time, which helps prevent overfitting. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_input (InputLayer)        [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization_1 (TextVecto (None, 290)          0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "universal_sentence_encoder (Ker (None, 512)          256797824   token_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 290, 25)      700         text_vectorization_1[1][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          65664       universal_sentence_encoder[1][0] \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50)           10200       embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 178)          0           dense_4[0][0]                    \n",
      "                                                                 bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 178)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 200)          35800       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5)            1005        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 256,911,193\n",
      "Trainable params: 113,369\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMBINING TOKEN AND CHAR DATA INTO A SINGLE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_char_token_data=tf.data.Dataset.from_tensor_slices((train_sentences,train_chars))#make data\n",
    "train_char_token_labels=tf.data.Dataset.from_tensor_slices((train_df_one_hot))#make labels\n",
    "train_char_token_dataset=tf.data.Dataset.zip((train_char_token_data,train_char_token_labels))#combine them and zip it \n",
    "train_char_token_dataset=train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)#convert them to batch with prefetch autotuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_char_token_data=tf.data.Dataset.from_tensor_slices((val_sentences,val_chars))\n",
    "val_char_token_labels=tf.data.Dataset.from_tensor_slices((val_df_one_hot))\n",
    "val_char_token_dataset=tf.data.Dataset.zip((val_char_token_data,val_char_token_labels))\n",
    "val_char_token_dataset=val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_char_token_data=tf.data.Dataset.from_tensor_slices((test_sentences,test_chars))\n",
    "test_char_token_labels=tf.data.Dataset.from_tensor_slices((test_df_one_hot))\n",
    "test_char_token_dataset=tf.data.Dataset.zip((test_char_token_data,test_char_token_labels)).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 26s 38ms/step - loss: 0.9711 - accuracy: 0.6103 - val_loss: 0.8000 - val_accuracy: 0.6895\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 22s 38ms/step - loss: 0.8019 - accuracy: 0.6861 - val_loss: 0.7236 - val_accuracy: 0.7230\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 22s 39ms/step - loss: 0.7762 - accuracy: 0.7004 - val_loss: 0.7007 - val_accuracy: 0.7359\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 20s 36ms/step - loss: 0.7458 - accuracy: 0.7240 - val_loss: 0.6777 - val_accuracy: 0.7487\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 19s 34ms/step - loss: 0.7475 - accuracy: 0.7167 - val_loss: 0.6651 - val_accuracy: 0.7513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ddda19ed00>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(train_char_token_dataset,epochs=5,steps_per_epoch=(0.1*len(train_char_token_dataset)),\n",
    "            validation_data=val_char_token_dataset,validation_steps=(0.1*len(val_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 18s 19ms/step - loss: 0.6666 - accuracy: 0.7471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6665907502174377, 0.7471203207969666]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(val_char_token_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 5 WITH PRETRAINED TOKEN EMBEDDINGS + CHARACTER EMBEDDINGS + POSITIONAL EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE PROCESS OF APPLYING YOUR OWN KNOWLEDGE TO BUILD THE INPUT IS CALLED AS FEATURE ENGINEERING!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIRST,WE NEED TO CREATE A POSITIONAL EMBEDDING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     15000\n",
       "1     15000\n",
       "2     15000\n",
       "3     15000\n",
       "4     14992\n",
       "5     14949\n",
       "6     14758\n",
       "7     14279\n",
       "8     13346\n",
       "9     11981\n",
       "10    10041\n",
       "11     7892\n",
       "12     5853\n",
       "13     4152\n",
       "14     2835\n",
       "15     1861\n",
       "16     1188\n",
       "17      751\n",
       "18      462\n",
       "19      286\n",
       "20      162\n",
       "21      101\n",
       "22       66\n",
       "23       33\n",
       "24       22\n",
       "25       14\n",
       "26        7\n",
       "27        4\n",
       "28        3\n",
       "29        1\n",
       "30        1\n",
       "Name: line_number, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"line_number\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.line_number.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_line_numbers_one_hot=tf.one_hot(train_df[\"line_number\"].to_numpy(),depth=15)\n",
    "val_line_numbers_one_hot=tf.one_hot(val_df[\"line_number\"].to_numpy(),depth=15)\n",
    "test_line_numbers_one_hot=tf.one_hot(test_df[\"line_number\"].to_numpy(),depth=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BY SETTING THE VALUE OF DEPTH TO 15 any \"line number \" value if it gets over 15 its values become tensors of all 0's where as any sample whose \"line number\" value is less than 15 gets turned into tensors of value 0's but with a 1 at the index equal to the \"line_number\" value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 15), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_line_numbers_one_hot[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    24468\n",
       "11    23639\n",
       "13    22113\n",
       "10    19400\n",
       "14    18438\n",
       "15    14610\n",
       "9     12285\n",
       "16    10768\n",
       "8      7464\n",
       "17     7429\n",
       "18     5202\n",
       "7      3353\n",
       "19     3344\n",
       "20     2480\n",
       "21     1281\n",
       "6      1146\n",
       "22      770\n",
       "23      759\n",
       "24      264\n",
       "5       215\n",
       "25      200\n",
       "26      182\n",
       "27       81\n",
       "29       58\n",
       "4        32\n",
       "31       31\n",
       "28       28\n",
       "Name: total_lines, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"total_lines\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.total_lines.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_lines_one_hot=tf.one_hot(train_df[\"total_lines\"].to_numpy(),depth=20)\n",
    "val_total_lines_one_hot=tf.one_hot(val_df[\"total_lines\"].to_numpy(),depth=20)\n",
    "test_total_lines_one_hot=tf.one_hot(test_df[\"total_lines\"].to_numpy(),depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 20), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total_lines_one_hot[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILDING THE TRIBRID EMBEDDING MODEL! 1.CREATE THE TOKEN INPUT,CHAR INPUT,LINE NUMBER INPUT AND THE TOTAL LINES INPUT\n",
    "2.COMBINE CHAR AND TOKEN EMBEDDING INTO A SINGLE HYBRID EMBEDDING THEN COMBINE THE POSITIONAL EMBEDDING WITH THE HYBRID EMBEDDING TO FIND THE TRIBRID EMBEDDING 3.COMPILE THE MODEL 4.FIT THE MODEL 5.EVALUATE THE MODEL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE SURE THAT WHEREVER U CONCATENATE U PROVIDE A NAME TO THAT LAYER OTHERWISE IT IS GOING TO THROW AN ERROR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Token inputs\n",
    "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
    "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
    "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
    "token_model = tf.keras.Model(inputs=token_inputs,\n",
    "                             outputs=token_outputs)\n",
    "\n",
    "# 2. Char inputs\n",
    "char_inputs = layers.Input(shape=((1,)), dtype=\"string\", name=\"char_inputs\")\n",
    "char_vectors = char_vectorizer(char_inputs)\n",
    "char_embeddings = char_embed(char_vectors)\n",
    "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n",
    "char_model = tf.keras.Model(inputs=char_inputs,\n",
    "                            outputs=char_bi_lstm)\n",
    "\n",
    "# 3. Line numbers inputs\n",
    "line_number_inputs = layers.Input(shape=((15,)), dtype=tf.int32, name=\"line_number_input\")\n",
    "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
    "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
    "                                   outputs=x)\n",
    "\n",
    "# 4. Total lines inputs\n",
    "total_lines_inputs = layers.Input(shape=((20,)), dtype=tf.int32, name=\"total_lines_input\")\n",
    "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
    "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
    "                                  outputs=y)\n",
    "\n",
    "# 5. Combine token and char embeddings into a hybrid embedding\n",
    "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output, \n",
    "                                                                              char_model.output])\n",
    "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
    "z = layers.Dropout(0.5)(z)\n",
    "\n",
    "# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n",
    "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
    "                                                                total_line_model.output,\n",
    "                                                                z])\n",
    "\n",
    "# 7. Create output layer\n",
    "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
    "\n",
    "# 8. Put together model\n",
    "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
    "                                 total_line_model.input,\n",
    "                                 token_model.input, \n",
    "                                 char_model.input],\n",
    "                         outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_inputs (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_inputs (InputLayer)       [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization_1 (TextVecto (None, 290)          0           char_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "universal_sentence_encoder (Ker (None, 512)          256797824   token_inputs[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 290, 25)      700         text_vectorization_1[5][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 128)          65664       universal_sentence_encoder[7][0] \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 64)           14848       embedding[5][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "token_char_hybrid_embedding (Co (None, 192)          0           dense_21[0][0]                   \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "line_number_input (InputLayer)  [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "total_lines_input (InputLayer)  [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 256)          49408       token_char_hybrid_embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 32)           512         line_number_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 32)           672         total_lines_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "token_char_positional_embedding (None, 320)          0           dense_22[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 5)            1605        token_char_positional_embedding[0\n",
      "==================================================================================================\n",
      "Total params: 256,931,233\n",
      "Trainable params: 133,409\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_5.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE ARE GOING TO APPLY LABEL SMOOTHING IN OUR LOSS FUNCTION WHICH IS A REGULARIZATION TECHNIQUE THAT INTRODUCES NOISE FOR THE LABELS WE SET THAT VALUE TO AROUND 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2),optimizer=tf.keras.optimizers.Adam(),metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> False\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n",
      "<module 'keras.layers' from 'c:\\\\Anaconda\\\\envs\\\\tensorflow_env\\\\lib\\\\site-packages\\\\keras\\\\layers\\\\__init__.py'> True\n"
     ]
    }
   ],
   "source": [
    "for layer in model_5.layers:\n",
    "    print(layers,layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO FIT THE DATA WE GOTTA CREATE THE TENSOR DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>,\n",
       " <PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create training and validation datasets (all four kinds of inputs)\n",
    "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # line numbers\n",
    "                                                                train_total_lines_one_hot, # total lines\n",
    "                                                                train_sentences, # train tokens\n",
    "                                                                train_chars)) # train chars\n",
    "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_df_one_hot) # train labels\n",
    "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n",
    "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
    "\n",
    "# Validation dataset\n",
    "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
    "                                                              val_total_lines_one_hot,\n",
    "                                                              val_sentences,\n",
    "                                                              val_chars))\n",
    "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_df_one_hot)\n",
    "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
    "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
    "\n",
    "# Check input shapes\n",
    "train_pos_char_token_dataset, val_pos_char_token_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_char_token_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "562/562 [==============================] - 19s 34ms/step - loss: 0.9457 - accuracy: 0.8267 - val_loss: 0.9340 - val_accuracy: 0.8361\n",
      "Epoch 2/5\n",
      "562/562 [==============================] - 19s 34ms/step - loss: 0.9264 - accuracy: 0.8440 - val_loss: 0.9255 - val_accuracy: 0.8428\n",
      "Epoch 3/5\n",
      "562/562 [==============================] - 21s 37ms/step - loss: 0.9207 - accuracy: 0.8449 - val_loss: 0.9276 - val_accuracy: 0.8361\n",
      "Epoch 4/5\n",
      "562/562 [==============================] - 21s 37ms/step - loss: 0.9290 - accuracy: 0.8400 - val_loss: 0.9187 - val_accuracy: 0.8378\n",
      "Epoch 5/5\n",
      "562/562 [==============================] - 24s 42ms/step - loss: 0.9275 - accuracy: 0.8434 - val_loss: 0.9186 - val_accuracy: 0.8408\n"
     ]
    }
   ],
   "source": [
    "# Fit the token, char and positional embedding model\n",
    "history_model_5 = model_5.fit(train_pos_char_token_dataset,\n",
    "                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
    "                              epochs=5,\n",
    "                              validation_data=val_pos_char_token_dataset,\n",
    "                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 20s 21ms/step - loss: 0.9149 - accuracy: 0.8467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9149022102355957, 0.8466503620147705]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.evaluate(val_pos_char_token_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING OUR MODEL!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_13_layer_call_and_return_conditional_losses, lstm_cell_13_layer_call_fn, lstm_cell_14_layer_call_and_return_conditional_losses, lstm_cell_14_layer_call_fn, lstm_cell_13_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tribrid_skimlit_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tribrid_skimlit_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model_5.save(\"tribrid_skimlit_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=\"tribrid_skimlit_model\"\n",
    "loaded_model=tf.keras.models.load_model(\"tribrid_skimlit_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW WE EVALUATE MODEL ON TEST DATASET!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_char_token_data=tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot,test_total_lines_one_hot,\n",
    "                                                             test_sentences,test_chars))\n",
    "test_pos_char_token_labels=tf.data.Dataset.from_tensor_slices(test_df_one_hot)\n",
    "test_pos_char_token_dataset=tf.data.Dataset.zip((test_pos_char_token_data,test_pos_char_token_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_inputs (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_inputs (InputLayer)       [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization_1 (TextVecto (None, None)         0           char_inputs[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "universal_sentence_encoder (Ker (None, 512)          256797824   token_inputs[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 25)     700         text_vectorization_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 128)          65664       universal_sentence_encoder[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 64)           14848       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "token_char_hybrid_embedding (Co (None, 192)          0           dense_21[0][0]                   \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "line_number_input (InputLayer)  [(None, 15)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "total_lines_input (InputLayer)  [(None, 20)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 256)          49408       token_char_hybrid_embedding[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 32)           512         line_number_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 32)           672         total_lines_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "token_char_positional_embedding (None, 320)          0           dense_22[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_layer (Dense)            (None, 5)            1605        token_char_positional_embedding[0\n",
      "==================================================================================================\n",
      "Total params: 256,931,233\n",
      "Trainable params: 133,409\n",
      "Non-trainable params: 256,797,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945/945 [==============================] - 146s 155ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 0, 2, 2, 4, 4, 4, 4, 1], dtype=int64)>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test dataset\n",
    "test_pred_probs = loaded_model.predict(val_pos_char_token_dataset,\n",
    "                                       verbose=1)\n",
    "test_preds = tf.argmax(test_pred_probs, axis=1)\n",
    "test_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.61 s\n",
      "Wall time: 6.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_pred_classes=[label_encoder.classes_[pred]for pred in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>IgE sensitization to Aspergillus fumigatus and...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>0.594026</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>It is not clear whether these patients would b...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>0.623225</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>We sought to determine whether a @-month cours...</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>0.351511</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Asthmatic patients who were IgE sensitized to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>0.819682</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Primary outcomes were improvement in quality o...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>0.869077</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Sixty-five patients were randomized .</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>0.599150</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Fifty-nine patients started treatment ( @ rece...</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>0.579494</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Fifty-six patients took the full @ months of m...</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>0.544970</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Between the voriconazole and placebo groups , ...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>0.827603</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>We were unable to show a beneficial effect of ...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>0.666145</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>Opioid antagonists ( e.g. , naltrexone ) and p...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>0.450668</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>The use of higher doses to achieve greater eff...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>0.589045</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>Combining naltrexone and alprazolam might safe...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>0.490198</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>The present pilot study tested the hypothesis ...</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>0.322060</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Eight nontreatment-seeking , stimulant-using i...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>0.819002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>METHODS</td>\n",
       "      <td>Subjective effects , psychomotor task performa...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>0.784856</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Oral d-amphetamine produced prototypical physi...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>0.478977</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Pretreatment with naltrexone , alprazolam , an...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>0.494566</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Naltrexone and alprazolam each significantly a...</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>0.531216</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>The combination attenuated a greater number of...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>0.528942</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0    BACKGROUND  IgE sensitization to Aspergillus fumigatus and...   \n",
       "1    BACKGROUND  It is not clear whether these patients would b...   \n",
       "2     OBJECTIVE  We sought to determine whether a @-month cours...   \n",
       "3       METHODS  Asthmatic patients who were IgE sensitized to ...   \n",
       "4       METHODS  Primary outcomes were improvement in quality o...   \n",
       "5       RESULTS              Sixty-five patients were randomized .   \n",
       "6       RESULTS  Fifty-nine patients started treatment ( @ rece...   \n",
       "7       RESULTS  Fifty-six patients took the full @ months of m...   \n",
       "8       RESULTS  Between the voriconazole and placebo groups , ...   \n",
       "9   CONCLUSIONS  We were unable to show a beneficial effect of ...   \n",
       "10   BACKGROUND  Opioid antagonists ( e.g. , naltrexone ) and p...   \n",
       "11   BACKGROUND  The use of higher doses to achieve greater eff...   \n",
       "12   BACKGROUND  Combining naltrexone and alprazolam might safe...   \n",
       "13    OBJECTIVE  The present pilot study tested the hypothesis ...   \n",
       "14      METHODS  Eight nontreatment-seeking , stimulant-using i...   \n",
       "15      METHODS  Subjective effects , psychomotor task performa...   \n",
       "16      RESULTS  Oral d-amphetamine produced prototypical physi...   \n",
       "17      RESULTS  Pretreatment with naltrexone , alprazolam , an...   \n",
       "18      RESULTS  Naltrexone and alprazolam each significantly a...   \n",
       "19      RESULTS  The combination attenuated a greater number of...   \n",
       "\n",
       "    line_number  total_lines   prediction  pred_prob  correct  \n",
       "0             0           10   BACKGROUND   0.594026     True  \n",
       "1             1           10   BACKGROUND   0.623225     True  \n",
       "2             2           10   BACKGROUND   0.351511    False  \n",
       "3             3           10      METHODS   0.819682     True  \n",
       "4             4           10      METHODS   0.869077     True  \n",
       "5             5           10      RESULTS   0.599150     True  \n",
       "6             6           10      RESULTS   0.579494     True  \n",
       "7             7           10      RESULTS   0.544970     True  \n",
       "8             8           10      RESULTS   0.827603     True  \n",
       "9             9           10  CONCLUSIONS   0.666145     True  \n",
       "10            0           11    OBJECTIVE   0.450668    False  \n",
       "11            1           11   BACKGROUND   0.589045     True  \n",
       "12            2           11   BACKGROUND   0.490198     True  \n",
       "13            3           11   BACKGROUND   0.322060    False  \n",
       "14            4           11      METHODS   0.819002     True  \n",
       "15            5           11      METHODS   0.784856     True  \n",
       "16            6           11      RESULTS   0.478977     True  \n",
       "17            7           11      RESULTS   0.494566     True  \n",
       "18            8           11      RESULTS   0.531216     True  \n",
       "19            9           11      RESULTS   0.528942     True  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[\"prediction\"]=test_pred_classes\n",
    "val_df[\"pred_prob\"]=tf.reduce_max(test_pred_probs,axis=1).numpy()\n",
    "val_df[\"correct\"]=val_df[\"prediction\"]==val_df[\"target\"]\n",
    "val_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>line_number</th>\n",
       "      <th>total_lines</th>\n",
       "      <th>prediction</th>\n",
       "      <th>pred_prob</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10034</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Secondary outcomes included time to TB treatme...</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>0.945100</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28193</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Primary outcome measures were symptom self-rat...</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>0.933174</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15769</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Dwellings in the ITN+IRS arm were sprayed with...</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>0.930662</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Participants were randomized to tadalafil @ mg...</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>0.930126</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20408</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>A double-blind , randomized , controlled trial...</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>0.924134</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Therefore , LA administration may be useful fo...</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>0.855424</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16599</th>\n",
       "      <td>RESULTS</td>\n",
       "      <td>All were examined by an ophthalmologist and ei...</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>0.855420</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18208</th>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>To compare pain response outcomes for patients...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>OBJECTIVE</td>\n",
       "      <td>0.853944</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10685</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>While both insertion methods proved equivalent...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>0.853121</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28950</th>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>Identifier : ISRCTN@ .</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>0.852618</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            target                                               text  \\\n",
       "10034      RESULTS  Secondary outcomes included time to TB treatme...   \n",
       "28193      RESULTS  Primary outcome measures were symptom self-rat...   \n",
       "15769      RESULTS  Dwellings in the ITN+IRS arm were sprayed with...   \n",
       "1027       RESULTS  Participants were randomized to tadalafil @ mg...   \n",
       "20408      RESULTS  A double-blind , randomized , controlled trial...   \n",
       "...            ...                                                ...   \n",
       "412        RESULTS  Therefore , LA administration may be useful fo...   \n",
       "16599      RESULTS  All were examined by an ophthalmologist and ei...   \n",
       "18208   BACKGROUND  To compare pain response outcomes for patients...   \n",
       "10685  CONCLUSIONS  While both insertion methods proved equivalent...   \n",
       "28950  CONCLUSIONS                             Identifier : ISRCTN@ .   \n",
       "\n",
       "       line_number  total_lines   prediction  pred_prob  correct  \n",
       "10034            4           18      METHODS   0.945100    False  \n",
       "28193            5           14      METHODS   0.933174    False  \n",
       "15769            4           18      METHODS   0.930662    False  \n",
       "1027             4           15      METHODS   0.930126    False  \n",
       "20408            2           18      METHODS   0.924134    False  \n",
       "...            ...          ...          ...        ...      ...  \n",
       "412             13           15  CONCLUSIONS   0.855424    False  \n",
       "16599            4           14      METHODS   0.855420    False  \n",
       "18208            0           11    OBJECTIVE   0.853944    False  \n",
       "10685            5            8      RESULTS   0.853121    False  \n",
       "28950           11           12   BACKGROUND   0.852618    False  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100_wrong=val_df[val_df[\"correct\"]==False].sort_values(\"pred_prob\",ascending=False)[:100]\n",
    "top_100_wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOP WRONG PREDICTIONS ARE AS FOLLOWS!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: RESULTS, Pred: METHODS, Prob: 0.945099949836731, Line number: 4, Total lines: 18\n",
      "\n",
      "Text:\n",
      "Secondary outcomes included time to TB treatment and mortality .\n",
      "\n",
      "-----\n",
      "\n",
      "Target: RESULTS, Pred: METHODS, Prob: 0.933173656463623, Line number: 5, Total lines: 14\n",
      "\n",
      "Text:\n",
      "Primary outcome measures were symptom self-rating scales ( Insomnia Severity Index -LSB- ISI -RSB- and the Montgomery sberg Depression Rating Scale -LSB- MADRS-S -RSB- ) , assessed before and after treatment with follow-up after @ and @ mo. .\n",
      "\n",
      "-----\n",
      "\n",
      "Target: RESULTS, Pred: METHODS, Prob: 0.9306617379188538, Line number: 4, Total lines: 18\n",
      "\n",
      "Text:\n",
      "Dwellings in the ITN+IRS arm were sprayed with two rounds of bendiocarb in @ .\n",
      "\n",
      "-----\n",
      "\n",
      "Target: RESULTS, Pred: METHODS, Prob: 0.9301260709762573, Line number: 4, Total lines: 15\n",
      "\n",
      "Text:\n",
      "Participants were randomized to tadalafil @ mg daily or placebo for @ months .\n",
      "\n",
      "-----\n",
      "\n",
      "Target: RESULTS, Pred: METHODS, Prob: 0.9241341948509216, Line number: 2, Total lines: 18\n",
      "\n",
      "Text:\n",
      "A double-blind , randomized , controlled trial was conducted at @ sites in the United States .\n",
      "\n",
      "-----\n",
      "\n",
      "Target: RESULTS, Pred: METHODS, Prob: 0.9217585325241089, Line number: 3, Total lines: 14\n",
      "\n",
      "Text:\n",
      "Clinic-derived systolic blood pressure obtained before , during , and after the trial were estimated using linear mixed models .\n",
      "\n",
      "-----\n",
      "\n",
      "Target: OBJECTIVE, Pred: METHODS, Prob: 0.9213846325874329, Line number: 4, Total lines: 14\n",
      "\n",
      "Text:\n",
      "The resource consumption , costs , and health-related quality of life were evaluated at baseline , and after @ and @ months by using statutory health insurance information and standardized questionnaires .\n",
      "\n",
      "-----\n",
      "\n",
      "Target: RESULTS, Pred: METHODS, Prob: 0.9164919853210449, Line number: 5, Total lines: 13\n",
      "\n",
      "Text:\n",
      "Secondary outcomes included measures of cardiovascular function , renal function , resource use , and adverse events .\n",
      "\n",
      "-----\n",
      "\n",
      "Target: RESULTS, Pred: METHODS, Prob: 0.914728581905365, Line number: 4, Total lines: 15\n",
      "\n",
      "Text:\n",
      "Systolic/diastolic blood pressure ( SBP/DBP ) was measured at week @ , @ and @ .\n",
      "\n",
      "-----\n",
      "\n",
      "Target: RESULTS, Pred: METHODS, Prob: 0.9129951000213623, Line number: 3, Total lines: 12\n",
      "\n",
      "Text:\n",
      "A total of @ patients with hypertension treated with @ mg olmesartan were randomized to receive combination treatment with @ mg azelnidipine ( O/A group ) or diuretics ( @ mg indapamide ; O/D group ) for @ months .\n",
      "\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in  top_100_wrong[0:10].itertuples():\n",
    "    _,target,text,line_number,total_lines,prediction,pred_prob,_=row\n",
    "    print(f\"Target: {target}, Pred: {prediction}, Prob: {pred_prob}, Line number: {line_number}, Total lines: {total_lines}\\n\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"-----\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE CAN IMPLEMENT THIS MODEL TO THE PUBMED MODEL ON THE BACKEND OF PUBMED SITE! IT CAN SAVE THE RESEARCHES LOT OF TIME AND EFFORT TO READ THROUGH THE DATA/ABSTRACTS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d429fc8f8d258f93e65df4f2c61dc899267107a5a109a617fa8f659faf2e1989"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
